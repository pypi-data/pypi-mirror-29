#!/usr/bin/env python
# encoding: utf-8

# The MIT License (MIT)

# Copyright (c) 2017-2018 CNRS

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# AUTHORS
# Herv√© BREDIN - http://herve.niderb.fr


from ._version import get_versions
__version__ = get_versions()['version']
del get_versions

import pandas as pd
import os.path as op
from pyannote.core import Segment, Timeline, Annotation
from pyannote.database import Database
from pyannote.database.protocol import SpeakerVerificationProtocol
from pyannote.database.protocol import SpeakerIdentificationProtocol


class VerificationVoxCeleb1(SpeakerVerificationProtocol):

    def _xxx_iter(self, subset):

        if not isinstance(subset, list):
            subsets = [subset]
        else:
            subsets = subset

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])
        data = data.groupby('verification')

        # segment                          uri                      start end  speaker      verification identification
        # A.J._Buckley/1zcIwhmdeo4_0000001 A.J._Buckley/1zcIwhmdeo4 14.7  22.8 A.J._Buckley dev          trn

        for subset in subsets:

            subset_data = data.get_group(subset)

            for uri, datum in subset_data.iterrows():

                annotation = Annotation(uri=uri)
                segment = Segment(0., datum.end - datum.start)
                annotation[segment] = datum.speaker

                annotated = annotation.get_timeline()

                current_file = {
                    'uri': uri,
                    'database': 'VoxCeleb',
                    'annotation': annotation,
                    'annotated': annotated,
                }

                yield current_file

    def _xxx_enrol_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        trial_csv = op.join(
            data_dir,
            'voxceleb1.verification.{subset}.csv'.format(subset=subset))
        trials = pd.read_csv(trial_csv)

        for model_id in trials['enrolment'].unique():

            try:
                row = data.ix[model_id]
            except KeyError as e:
                # file_id = model_id.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            uri = model_id
            segment = Segment(0., row.end - row.start)
            current_enrolment = {
                'database': 'VoxCeleb',
                'uri': uri,
                'model_id': model_id,
                'enrol_with': Timeline(uri=uri, segments=[segment]),
            }

            yield current_enrolment

    def _xxx_try_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        trial_csv = op.join(
            data_dir,
            'voxceleb1.verification.{subset}.csv'.format(subset=subset))
        trials = pd.read_csv(trial_csv)

        for _, trial in trials.iterrows():

            model_id = trial.enrolment

            try:
                _ = data.ix[model_id]
            except KeyError as e:
                # file_id = model_id.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            try:
                row = data.ix[trial.test]
            except KeyError as e:
                # file_id = trial.test.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            uri = trial.test
            segment = Segment(0., row.end - row.start)
            reference = trial.trial

            current_trial = {
                'database': 'VoxCeleb',
                'uri': uri,
                'try_with': Timeline(uri=uri, segments=[segment]),
                'model_id': model_id,
                'reference': bool(reference),
            }

            yield current_trial

    # TRAIN

    def trn_iter(self):
        return self._xxx_iter(['trn', 'dev'])

    def trn_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def trn_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    # DEVELOPMENT

    def dev_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    def dev_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    def dev_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    # TEST

    def tst_iter(self):
        return self._xxx_iter('tst')

    def tst_enrol_iter(self):
        return self._xxx_enrol_iter('tst')

    def tst_try_iter(self):
        return self._xxx_try_iter('tst')


class VerificationVoxCeleb1WithDevelopment(VerificationVoxCeleb1):

        def trn_iter(self):
            return self._xxx_iter('trn')

        def dev_iter(self):
            return self._xxx_iter('dev')

        def dev_enrol_iter(self):
            return self._xxx_enrol_iter('dev')

        def dev_try_iter(self):
            return self._xxx_try_iter('dev')


class VerificationVoxCeleb1_Whole(SpeakerVerificationProtocol):

    def _xxx_iter(self, subset):

        if not isinstance(subset, list):
            subsets = [subset]
        else:
            subsets = subset

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])
        data = data.groupby('verification')

        for subset in subsets:

            subset_data.get_group(subset)

            for uri, rows in subset_data.groupby('uri'):
                annotation = Annotation(uri=uri)
                for row in rows.itertuples():
                    segment = Segment(row.start, row.end)
                    annotation[segment] = row.speaker
                annotated = annotation.get_timeline()

                current_file = {
                    'uri': uri,
                    'database': 'VoxCeleb',
                    'annotation': annotation,
                    'annotated': annotated,
                }

                yield current_file

    def _xxx_enrol_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        trial_csv = op.join(
            data_dir,
            'voxceleb1.verification.{subset}.csv'.format(subset=subset))
        trials = pd.read_csv(trial_csv)

        for model_id in trials['enrolment'].unique():

            try:
                row = data.ix[model_id]
            except KeyError as e:
                # file_id = model_id.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            uri = row.uri
            segment = Segment(row.start, row.end)
            current_enrolment = {
                'database': 'VoxCeleb',
                'uri': uri,
                'model_id': model_id,
                'enrol_with': Timeline(uri=uri, segments=[segment]),
            }

            yield current_enrolment

    def _xxx_try_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        trial_csv = op.join(
            data_dir,
            'voxceleb1.verification.{subset}.csv'.format(subset=subset))
        trials = pd.read_csv(trial_csv)

        for trial in trials.itertuples():

            model_id = trial.enrolment

            try:
                _ = data.ix[model_id]
            except KeyError as e:
                # file_id = model_id.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            try:
                row = data.ix[trial.test]
            except KeyError as e:
                # file_id = trial.test.split('/')[1][:-8]
                # msg = '{file_id} marked as duplicate in VoxCeleb 1.1'
                # warnings.warn(msg.format(file_id=file_id))
                continue

            uri = row.uri
            segment = Segment(row.start, row.end)
            reference = row.trial

            current_trial = {
                'database': 'VoxCeleb',
                'uri': uri,
                'try_with': Timeline(uri=uri, segments=[segment]),
                'model_id': model_id,
                'reference': bool(reference),
            }

            yield current_trial

    # TRAIN

    def trn_iter(self):
        return self._xxx_iter(['trn', 'dev'])

    def trn_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def trn_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    # DEVELOPMENT

    def dev_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    def dev_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    def dev_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    # TEST

    def tst_iter(self):
        return self._xxx_iter('tst')

    def tst_enrol_iter(self):
        return self._xxx_enrol_iter('tst')

    def tst_try_iter(self):
        return self._xxx_try_iter('tst')


class VerificationVoxCeleb1_WholeWithDevelopment(VerificationVoxCeleb1_Whole):

        def trn_iter(self):
            return self._xxx_iter('trn')

        def dev_iter(self):
            return self._xxx_iter('dev')

        def dev_enrol_iter(self):
            return self._xxx_enrol_iter('dev')

        def dev_try_iter(self):
            return self._xxx_try_iter('dev')


class IdentificationVoxCeleb1(SpeakerIdentificationProtocol):

    def trn_iter(self):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])
        data = data.groupby('identification').get_group('trn')

        for uri, datum in data.iterrows():

            annotation = Annotation(uri=uri)
            segment = Segment(0., datum.end - datum.start)
            annotation[segment] = datum.speaker

            annotated = annotation.get_timeline()

            current_file = {
                'uri': uri,
                'database': 'VoxCeleb',
                'annotation': annotation,
                'annotated': annotated,
            }

            yield current_file

    def common_enrol_iter(self):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        data = data.groupby('identification').get_group('trn')

        for model_id, model_rows in data.groupby('speaker'):
            uris = []
            enrol_with = []

            for uri, row in model_rows.iterrows():
                uris.append(uri)
                segment = Segment(0., row.end - row.start)
                enrol_with.append(Timeline(uri=uri, segments=[segment]))

            current_enrolment = {
                'database': 'VoxCeleb',
                'model_id': model_id,
                'uri': uris,
                'enrol_with': enrol_with
            }

            yield current_enrolment

    def trn_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def dev_enrol_iter(self):
        return self.common_enrol_iter()

    def tst_enrol_iter(self):
        return self.common_enrol_iter()

    def _xxx_try_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        data = data.groupby('identification').get_group(subset)

        for uri, trial in data.iterrows():

            reference = trial.speaker
            segment = Segment(0., trial.end - trial.start)

            current_trial = {
                'database': 'VoxCeleb',
                'uri': uri,
                'try_with': Timeline(uri=uri, segments=[segment]),
                'reference': reference,
            }

            yield current_trial

    def trn_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def dev_try_iter(self):
        return self._xxx_try_iter('dev')

    def tst_try_iter(self):
        return self._xxx_try_iter('tst')

    def _xxx_iter(self, subset):

        for current_trial in self._xxx_try_iter(subset):

            annotated = current_trial['try_with']
            uri = current_trial['uri']
            annotation = Annotation(uri=uri)
            label = current_trial['reference']
            for s, segment in enumerate(annotated):
                annotation[segment, s] = label

            yield {
                'database': 'VoxCeleb',
                'uri': uri,
                'annotated': annotated,
                'annotation': annotation
            }

    # shouldn't be used for speaker identification experiments
    # this is here just for convenience to iterate over all trial files
    def dev_iter(self):
        return self._xxx_iter('dev')

    # shouldn't be used for speaker identification experiments
    # this is here just for convenience to iterate over all trial files
    def tst_iter(self):
        return self._xxx_iter('tst')


class IdentificationVoxCeleb1_Whole(SpeakerIdentificationProtocol):

    def trn_iter(self):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])
        data = data.groupby('identification').get_group('trn')

        for uri, rows in data.groupby('uri'):
            annotation = Annotation(uri=uri)
            for row in rows.itertuples():
                segment = Segment(row.start, row.end)
                annotation[segment] = row.speaker
            annotated = annotation.get_timeline()

            current_file = {
                'uri': uri,
                'database': 'VoxCeleb',
                'annotation': annotation,
                'annotated': annotated,
            }

            yield current_file

    def dev_iter(self):
        raise NotImplementedError(
            'This protocol does not define a development set.')

    def tst_iter(self):
        raise NotImplementedError(
            'This protocol does not define a test set.')

    def common_enrol_iter(self):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        data = data.groupby('identification').get_group('trn')

        for model_id, model_rows in data.groupby('speaker'):
            uris = []
            enrol_with = []
            for uri, rows in model_rows.groupby('uri'):
                uris.append(uri)
                segments = []
                for row in rows.itertuples():
                    segments.append(Segment(row.start, row.end))
                enrol_with.append(Timeline(uri=uri, segments=segments))

            current_enrolment = {
                'database': 'VoxCeleb',
                'model_id': model_id,
                'uri': uris,
                'enrol_with': enrol_with
            }

            yield current_enrolment

    def trn_enrol_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def dev_enrol_iter(self):
        return self.common_enrol_iter()

    def tst_enrol_iter(self):
        return self.common_enrol_iter()

    def _xxx_try_iter(self, subset):

        data_dir = op.join(op.dirname(op.realpath(__file__)), 'data')
        data_csv = op.join(data_dir, 'voxceleb1.csv')
        data = pd.read_csv(data_csv, index_col=['segment'])

        data = data.groupby('identification').get_group(subset)

        for trial in data.itertuples():

            reference = trial.speaker
            uri = trial.uri
            segment = Segment(trial.start, trial.end)

            current_trial = {
                'database': 'VoxCeleb',
                'uri': uri,
                'try_with': Timeline(uri=uri, segments=[segment]),
                'reference': reference,
            }

            yield current_trial

    def trn_try_iter(self):
        raise NotImplementedError(
            'This protocol does not define trials on the training set.')

    def dev_try_iter(self):
        return self._xxx_try_iter('dev')

    def tst_try_iter(self):
        return self._xxx_try_iter('tst')


class VoxCeleb(Database):
    """VoxCeleb: a large-scale speaker identification dataset

Citation
========
@InProceedings{Nagrani17,
  author       = "Nagrani, A. and Chung, J.~S. and Zisserman, A.",
  title        = "VoxCeleb: a large-scale speaker identification dataset",
  booktitle    = "INTERSPEECH",
  year         = "2017",
}

Webpage
=======
http://www.robots.ox.ac.uk/~vgg/data/voxceleb/

    """
    def __init__(self, preprocessors={}, **kwargs):
        super(VoxCeleb, self).__init__(preprocessors=preprocessors, **kwargs)

        self.register_protocol(
            'SpeakerVerification', 'VoxCeleb1_Whole',
            VerificationVoxCeleb1_Whole)

        self.register_protocol(
            'SpeakerVerification', 'VoxCeleb1', VerificationVoxCeleb1)

        self.register_protocol(
            'SpeakerVerification', 'VoxCeleb1_UVW',
            VerificationVoxCeleb1_WholeWithDevelopment)

        self.register_protocol(
            'SpeakerVerification', 'VoxCeleb1_UVW',
            VerificationVoxCeleb1WithDevelopment)


        self.register_protocol(
            'SpeakerIdentification', 'VoxCeleb1_Whole',
            IdentificationVoxCeleb1_Whole)

        self.register_protocol(
            'SpeakerIdentification', 'VoxCeleb1', IdentificationVoxCeleb1)
