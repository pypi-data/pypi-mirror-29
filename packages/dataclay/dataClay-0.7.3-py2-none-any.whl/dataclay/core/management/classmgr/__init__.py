from dataclay.core.primitives import *
from jinja2 import Template
from logging import getLogger, DEBUG
from lru import LRU

from ..baseclass import ManagementObject


logger = getLogger(__name__)

NATIVE_PACKAGES = {
    'numpy',
    'caffe',
    'csv',
}

STATIC_ATTRIBUTE_FOR_EXTERNAL_INIT = 'DCLAY_FORCE_EXTERNAL_INIT'


# Static Template for the source code of the classes
py_code = Template("""
class {{ class_name }}({{ parent_name }}):
    \"\"\"Auto-generated code for class {{ metaclass.name }}

    This source code has been generated by the dataclay MetaClass container. There is
    some work ToDo yet.
    \"\"\"
{% for c in imp_codes %}
{{ c }}{% endfor %}
""")

stub_only_def = Template("""
    @dclayEmptyMethod
    def {{ func_name }}(
            self{% for param in param_names %}{% if loop.first %},{% endif %}
            {{ param }}{% if loop.last %}
    {% endif %}{% else %}
    {% endfor %}):
        raise NotImplementedError("Language Error: Method {{ func_name }} is not available for Python")
""")


# Added descriptor and typeName
class Type(ManagementObject):
    _fields = ["id",  # sql id, internals
               "descriptor",
               "signature",
               "typeName",
               "includes",
               ]

    _internal_fields = ["languageDepInfos",
                        ]

    # ToDo: Correct Type methods
    @staticmethod
    def build_from_type(type_instance):
        """Build a Type from a type instance (of a decorator, typically).
        :param type_instance: The instance passed to the decorator. Note that
        this may be a real type (like int, str, a custom DataClayObject class...)
        or it may be a string like 'list<storageobject>'.
        :return: A Type instance.
        """
        from dataclay.managers.classes import DataClayObject
        try:
            return instance_types[type_instance]
        except KeyError:
            pass
        if isinstance(type_instance, str):
            return Type.build_from_docstring(type_instance)
        elif issubclass(type_instance, DataClayObject):
            full_name = type_instance._dclay_class_extradata.full_name
            namespace = type_instance._dclay_class_extradata.namespace
            # FixMe: UserType seems to have wrong fields
            return UserType(namespace=namespace,
                            typeName=full_name,
                            signature=("L%s;" % full_name).replace(".", "/"),
                            includes=[])
        else:
            raise RuntimeError("Using a type instance is only supported for "
                               "language primitives and DataClayObjects")

    @staticmethod
    def build_from_docstring(type_str):
        
        """Build a Type from the docstring name.
        :param type_str: The string the registrator used for that Type.
        :return: A Type instance.

        This function recognizes the different kinds of types the user can use
        like 'int', 'float' for Python-native primitive types, 'list<...>'
        for Python-specific types or full class names for registered classes.
        """
        
        logger.debug("Building from " + type_str)

        try:
            return docstring_types[type_str]
        except KeyError:
            pass

        if type_str.startswith("list") or \
           type_str.startswith("tuple") or \
           type_str.startswith("dict") or \
           type_str == "str":
            # In Python we decided (COMPSs + Hecuba + dataClay) to use basic_type<sub_type>
            # but not sure whereelse is expecting basic_type[sub_type]... but maybe
            # [] notation is only used for array-based containers. Proceed with caution!
            return Type(signature="python.%s" % type_str.replace("<", "[").replace(">", "]"),
                        includes=[])

        elif type_str == "anything" or type_str == "storageobject":
            return Type(signature=type_str,
                        includes=[])
        else:
            namespace, full_name = type_str.split('.', 1)

            if namespace in NATIVE_PACKAGES:
                return Type(signature=type_str,
                            includes=[])
            else:
                return UserType(namespace=namespace,
                                typeName=full_name,
                                signature=("L%s;" % full_name).replace(".", "/"),
                                includes=[])


# Deleted name from fields
class UserType(Type):
    _fields = [
               "namespace",
               ]

    _internal_fields = ["classID",
                        ]


class AccessedImplementation(ManagementObject):
    _fields = ["id",  # sql id, internals
               "namespace",
               "className",
               "opSignature",
               "implPosition",
               ]

    _internal_fields = ["implementationID",
                        ]


class AccessedProperty(ManagementObject):
    _fields = [
               "id",  # sql id, internals
               "namespace",
               "className",
               "name",
               ]

    _internal_fields = ["propertyID",
                        ]


# Modified abstract with isAbstract, deleted dcID and implID as internal_fields
class MetaClass(ManagementObject):
    _fields = ["dataClayID",
               "namespace",
               "name",
               "parentType",
               "properties",
               "operations",
               "isAbstract",
               "languageDepInfos",
               "ecas"
               ]

    _internal_fields = ["namespaceID",
                        # Internal memoization for get_operation method
                        "_implementation_id_to_operation_cache", ]
    
    _typed_fields = {"parentType": Type}
        
    # ToDo: Correct MetaClass methods
    def get_operation_from_name(self, op_name):
        """Return the operation from its name."""
        # FIXME performance-wise, this is Bad(TM).

        for op in self.operations:
            if op.name == op_name:
                return op

        raise KeyError("Operation with name %s was not found in dataClay class %s" % 
                       (op_name, self.name))

    def get_operation(self, implementation_id):
        """Return an Operation (management object) from an ImplementationID

        :param uuid.UUID implementation_id: The requested ImplementationID

        Given the UUID for a certain Implementation, lookup and return the
        corresponding Operation. Note that this method is memoized (cached) in
        order to improve performance (given that the lookup is slow).
        """
        if not hasattr(self, "_implementation_id_to_operation_cache"):
            # TODO: remove this hardcoded value for the LRU
            setattr(self, "_implementation_id_to_operation_cache", LRU(50))

        # If the key is in there, easy!
        try:
            return self._implementation_id_to_operation_cache[implementation_id]
        except KeyError:
            pass

        # Bad luck! Seems we must do the expensive lookup now
        for op in self.operations:
            for imp in op.implementations:
                if imp.dataClayID == implementation_id:
                    # Found it, store it in the LRU and also return it
                    self._implementation_id_to_operation_cache[implementation_id] = op
                    return op

        raise KeyError("Operation for ImplementationID {%s} not found in class %s (in namespace %s)" % 
                       (implementation_id, self.name, self.namespace))

    def juxtapose_code(self, exeenv_flag=False):
        """Return the complete source code for the current MetaClass.

        :param exeenv_flag: Set to true to generate code for the ExecutionEnvironment.
        :return: A valid source for this class.

        Note that this class will use the "local_implementation" of its
        operations > implementations when available. Undefined behaviour if
        not available.

        In scenarios where implementations are *not* `PythonImplementation` a
        pure-stub (intended for only persistent work mode) function is used. If
        the constructor is one of those non-Python methods, then the class is
        flagged as EXTERNAL_INIT only (see ExecutionGateway for further info).
        """
        from dataclay.core.management.classmgr.python import PythonImplementation

        imp_codes = list()

        # Java may have multiple overloads, ignore them
        ops_done = set()

        for op in self.operations:
            if op.name.startswith("$$"):
                # logger.debug("Ignoring method %s because it is a getter/setter", op.name)
                continue

            if op.name in ops_done:
                # logger.info("I may have found an overload for operation %s --ignoring", op.name)
                continue
            ops_done.add(op.name)

            if len(op.implementations) != 1:
                raise NotImplementedError("Found %d operations, but currently"
                                          " I only support one" % op.implementations)
            imp = op.implementations[0]

            if isinstance(imp, PythonImplementation):
                # ToDo fix behaviour regarding exeenv_flag, local/remote implementation
                imp_codes.append(imp.code)
            else:
                if op.name == "__init__" or op.name == "<init>":
                    imp_codes.append("\n    %s = %s" % (
                        STATIC_ATTRIBUTE_FOR_EXTERNAL_INIT, str(True)))
                    # Override the name, because java's <init> should become __init__
                    op.name = "__init__"

                imp_codes.append(stub_only_def.render({
                    "func_name": op.name,
                    "param_names": op.paramOrder,
                }))

        return py_code.render({
            "class_name": self.name.rsplit('.', 1)[-1],
            "parent_name": self.parentType.typeName if self.parentType else "DataClayObject",
            "metaclass": self,
            "imp_codes": imp_codes,
        })


# Added descriptor and nameAndDescriptor, modified isAbstract/isStaticConstructor, deleted dataclayID
class Operation(ManagementObject):
    _fields = ["dataClayID",
               "namespace",
               "className",
               "descriptor",
               "signature",
               "name",
               "nameAndDescriptor",
               "params",
               "paramOrder",
               "returnType",
               "implementations",
               "isAbstract",
               "isStaticConstructor",
               ]

    _internal_fields = ["metaClassID",
                        "namespaceID",
                        "languageDepInfos",
                        "annotations"
                        ]

    _typed_fields = {"returnType": Type}


# Added setterImplementationID, deleted dataclayID
class Property(ManagementObject):
    _fields = ["dataClayID",
               "namespace",
               "className",
               "name",
               "position",
               "type",
               "beforeUpdate",
               "afterUpdate"
               ]

    _internal_fields = ["getterOperationID",
                        "getterImplementationID",
                        "setterImplementationID",
                        "setterOperationID",
                        "namespaceID",
                        "metaClassID",
                        "languageDepInfos",
                        "annotations"
                        ]

    _typed_fields = {"type": Type}


class Implementation(ManagementObject):
    _fields = ["dataClayID",
               "responsibleAccountName",
               "namespace",
               "className",
               "opNameAndDescriptor",
               "position",
               "includes",
               "accessedProperties",
               "accessedImplementations",
               "requiredQuantitativeFeatures",
               "requiredQualitativeFeatures",
               ]

    _internal_fields = ["operationID",
                        "metaClassID",
                        "responsibleAccountID",
                        "namespaceID",
                        "prefetchingInfo",
                        ]


class LanguageDependantClassInfo(ManagementObject):
    _fields = []


class LanguageDependantOperationInfo(ManagementObject):
    _fields = []


class LanguageDependantPropertyInfo(ManagementObject):
    _fields = []


class LanguageDependantTypeInfo(ManagementObject):
    _fields = []


# Note that the class_id of language types are null since "dataClay 2"
mapping_table = [
    (("int", int, Int(64)), Type(
        signature='J',
        includes=[],
    )),
    (("float", float, Float(64)), Type(
        signature='D',
        includes=[],
    )),
    (("bool", bool, Bool()), Type(
        signature='Z',
        includes=[],
    )),
    (("None", None, Null()), Type(
        signature='V',
        includes=[],
    )),
]

# Statically build the dictionaries for fast and easy lookup
docstring_types = dict(map(
    lambda (what, type_c): (what[0], type_c),
    mapping_table))

instance_types = dict(map(
    lambda (what, type_c): (what[1], type_c),
    mapping_table))

serialization_types = dict(map(
    lambda (what, type_c): (type_c.signature, what[2]),
    mapping_table
))
