{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _recorderperf:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Implementing efficient recorders\n",
    "\n",
    "When taking time series data during a simulation, a callable gets passed in and called every generation.  Therefore, the details of that callable can have a big effect on run time.  Here, we explore different ways to write such \"recorders\" and benchmark them."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Background reading:\n",
    "\n",
    "* :ref:`processingpops`\n",
    "* :ref:`processingpopsNP`\n",
    "* :ref:`cython`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need is a function that we can reuse in order to evolve a population with a recorder.  That function is shown in the next block.  We are opting to require that recorders be constructed with the length of the simulation (in generation).  This requirement means that our recorders can pre-allocate the memory for recorded data, which is an optional optimization.\n",
    "\n",
    "Here's the code for evolving a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fwdpy11\n",
    "import fwdpy11.model_params\n",
    "import fwdpy11.fitness\n",
    "import fwdpy11.wright_fisher\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evolve(args):\n",
    "    \"\"\"\n",
    "    Evolve function takes an initial\n",
    "    population size,\n",
    "    RNG seed, and the type name of a recorder as\n",
    "    arguments.\n",
    "    \"\"\"\n",
    "    N,seed,recorderType,theta,rho,simlen=args\n",
    "    pop = fwdpy11.SlocusPop(N)\n",
    "    rng=fwdpy11.GSLrng(seed)\n",
    "    nrate=theta/float(4*N)\n",
    "    recrate=rho/float(4*N)\n",
    "    params=fwdpy11.model_params.SlocusParams(\n",
    "        nregions=[fwdpy11.Region(0,1,1)],\n",
    "        sregions=[fwdpy11.ExpS(0,1,1,-0.1,1.0)],\n",
    "        recregions=[fwdpy11.Region(0,1,1)],\n",
    "        gvalue=fwdpy11.fitness.SlocusAdditive(2.0),\n",
    "        demography=np.array([N]*simlen,dtype=np.uint32),\n",
    "        rates=(nrate,5e-3,recrate))\n",
    "    recorder = None\n",
    "    if recorderType is not None:\n",
    "        try:\n",
    "            recorder=recorderType(simlen,N)\n",
    "        except:\n",
    "            recorder=recorderType(simlen)\n",
    "    print(type(recorder))\n",
    "    fwdpy11.wright_fisher.evolve(rng,pop,params,recorder)\n",
    "    if recorder is not None:\n",
    "        return recorder.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first--how long does a simulation take with no recorder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "<class 'NoneType'>\n",
      "1 loop, best of 3: 218 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit evolve((1000,42,None,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing recorders in Python\n",
    "\n",
    "Our first recorder will do the following:\n",
    "\n",
    "1. Calculate population mean fitness\n",
    "2. Calculate the sum of effect sizes on each gamete in each diploid, and store the mean.\n",
    "\n",
    "This is not the most interesting thing to record about a population, but it is a useful example because it requires operations on most of the data in a population.\n",
    "\n",
    "Here is our first version, written in fairly plain Python.  Our only NumPy use is for intermediate data containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PyRecorder(object):\n",
    "    def __init__(self,simlen,N):\n",
    "        #An index variable referring to where we will next store data\n",
    "        self.i = 0\n",
    "        #Pre-allocate a structured array for our data.\n",
    "        #s1 and s2 are the mean sums of effect sizes on gamete 1 and 2, resp.\n",
    "        self.data=np.array([(-1,np.nan,np.nan,np.nan)]*simlen,\n",
    "                          dtype=[('generation',np.uint32),\n",
    "                                ('wbar',np.float),\n",
    "                                ('s1',np.float),\n",
    "                                ('s2',np.float)])\n",
    "        self.fitness = np.zeros(N,dtype=np.float)\n",
    "        self.nmuts1 = np.zeros(N,dtype=np.float)\n",
    "        self.nmuts2 = np.zeros(N,dtype=np.float)\n",
    "    def __call__(self,pop):\n",
    "        j=0\n",
    "        for dip in pop.diploids:\n",
    "            self.fitness[j]=dip.w\n",
    "            n1 = 0.\n",
    "            for key in pop.gametes[dip.first].smutations:\n",
    "                n1 += pop.mutations[key].s\n",
    "            n2 = 0.\n",
    "            for key in pop.gametes[dip.second].smutations:\n",
    "                n2 += pop.mutations[key].s\n",
    "            self.nmuts1[j]=n1\n",
    "            self.nmuts2[j]=n2\n",
    "            j+=1\n",
    "        self.data[self.i] = (pop.generation,\n",
    "                             self.fitness.mean(),\n",
    "                             self.nmuts1.mean(),\n",
    "                             self.nmuts2.mean())\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PyRecorder'>\n",
      "<class '__main__.PyRecorder'>\n",
      "<class '__main__.PyRecorder'>\n",
      "<class '__main__.PyRecorder'>\n",
      "1 loop, best of 3: 54.7 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve((1000,42,PyRecorder,100.,100.,500))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The code block below shows a Python recorder optimized using NumPy as described in :ref:`processingpopsNP`.  These methods allow more compact code because you can use numpy arrays as indexes for other numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PyRecorder2(object):\n",
    "    def __init__(self,simlen):\n",
    "        self.i = 0\n",
    "        self.data=np.array([(-1,np.nan,np.nan,np.nan)]*simlen,\n",
    "                          dtype=[('generation',np.uint32),\n",
    "                                ('wbar',np.float),\n",
    "                                ('s1',np.float),\n",
    "                                ('s2',np.float)])\n",
    "    def __call__(self,pop):\n",
    "        wbar = np.array(pop.diploids.trait_array())['w'].mean()\n",
    "        esizes = np.array(pop.mutations.array())['s']\n",
    "        j=0\n",
    "        nm1=0.\n",
    "        nm2=0.\n",
    "        for dip in pop.diploids:\n",
    "            nm1 += esizes[np.array(pop.gametes[dip.first].smutations)].sum()\n",
    "            nm2 += esizes[np.array(pop.gametes[dip.second].smutations)].sum()\n",
    "            j+=1\n",
    "            \n",
    "        self.data[self.i] = (pop.generation,wbar,nm1/float(pop.N),nm2/float(pop.N))\n",
    "        self.i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PyRecorder2'>\n",
      "<class '__main__.PyRecorder2'>\n",
      "<class '__main__.PyRecorder2'>\n",
      "<class '__main__.PyRecorder2'>\n",
      "1 loop, best of 3: 36.6 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve((1000,42,PyRecorder2,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside\n",
    "\n",
    "It is important to keep in mind that not all Python-based samplers need affect run times to the degree shown above!  The above examples are somewhat designed to be worst-case, as they are forcing Python to do a lot of stuff that it cannot optimize.  Let's take a look at another sampler, which generates a genotype matrix for 200 diploids: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fwdpy11.sampling\n",
    "\n",
    "np.random.seed(42)\n",
    "class MatrixSampler(object):\n",
    "    def __init__(self,simlen):  #the simlen arg is ignored\n",
    "        self.data=[]\n",
    "    def __call__(self,pop):\n",
    "        individuals = np.random.choice(pop.N,200,replace=False)\n",
    "        keys = fwdpy11.sampling.mutation_keys(pop,individuals)\n",
    "        neutral_sorted_keys=[i for i in sorted(keys[0],key=lambda x,m=pop.mutations: m[x[0]].pos)]\n",
    "        selected_sorted_keys=[i for i in sorted(keys[1],key=lambda x,m=pop.mutations: m[x[0]].pos)]\n",
    "        dm = fwdpy11.sampling.genotype_matrix(pop,individuals,neutral_sorted_keys,selected_sorted_keys)\n",
    "        self.data.append(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.MatrixSampler'>\n",
      "<class '__main__.MatrixSampler'>\n",
      "<class '__main__.MatrixSampler'>\n",
      "<class '__main__.MatrixSampler'>\n",
      "1 loop, best of 3: 2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve((1000,42,MatrixSampler,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  The reason is because most of fwdpy11's built-in functionality is using C++ behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Cython to speed things up.\n",
    "\n",
    "So our Python-only recorders are slowing things down a lot.  Let's see if we can improve things with Cython.  The key here is to use Cython's typed memory views and \"directives\" to move as many operations as possible from Python to C++.  We will also leverage fwpy11's integration with Numpy to get extra speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython --cplus --compile-args=-O3 --compile-args=-std=c++11 -3\n",
    "from libcpp.vector cimport vector\n",
    "from libc.stdint cimport uint32_t\n",
    "from cython.view cimport array as cvarray\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "#A nice feature of Cython is\n",
    "#implicit struct-to-dict conversion,\n",
    "#so we define a structure to hold our data:\n",
    "cdef struct my_data:\n",
    "    uint32_t generation\n",
    "    double wbar,s1,s2\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cdef inline double sum_e(uint32_t[:] keys,double[:] esizes) nogil:\n",
    "    cdef size_t i = 0, l = keys.shape[0]\n",
    "    cdef double t = 0.\n",
    "    while i < l:\n",
    "        t += esizes[keys[i]]\n",
    "        i+=1\n",
    "    return t\n",
    "\n",
    "cdef class CyRecorder(object):\n",
    "    #Cython can convert C++ vectors to\n",
    "    #Python lists.  Thus, we can hold\n",
    "    #our struct in a vector and it'll \n",
    "    #be converted to a list of dicts\n",
    "    #when we ask for it in Python.\n",
    "    #We mark the data as a readonly\n",
    "    #attribute so that users can't modify it.\n",
    "    cdef readonly vector[my_data] data\n",
    "    cdef double[:] esizes_view\n",
    "    def __cinit__(self,uint32_t simlen):\n",
    "        self.data = vector[my_data]()\n",
    "        self.data.reserve(simlen)\n",
    "    @cython.cdivision(True)\n",
    "    @cython.boundscheck(False)\n",
    "    @cython.wraparound(False)\n",
    "    def __call__(self,pop):\n",
    "        cdef double wbar = np.array(pop.diploids.trait_array())['w'].mean()\n",
    "        cdef np.ndarray[double,ndim=1] esizes = np.array(pop.mutations.array())['s']\n",
    "        cdef my_data d\n",
    "        self.esizes_view = esizes\n",
    "        cdef double N = <double>(pop.N)\n",
    "        cdef double t1=0.,t2=0.\n",
    "        for dip in pop.diploids:\n",
    "            t1 += sum_e(pop.gametes[dip.first].smutations,self.esizes_view)\n",
    "            t2 += sum_e(pop.gametes[dip.second].smutations,self.esizes_view)\n",
    "        d.generation = pop.generation\n",
    "        d.wbar = wbar\n",
    "        d.s1 = t1/N\n",
    "        d.s2 = t2/N\n",
    "        self.data.push_back(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_cython_magic_c1fa566bdd971718f341148a046f55b5.CyRecorder'>\n",
      "<class '_cython_magic_c1fa566bdd971718f341148a046f55b5.CyRecorder'>\n",
      "<class '_cython_magic_c1fa566bdd971718f341148a046f55b5.CyRecorder'>\n",
      "<class '_cython_magic_c1fa566bdd971718f341148a046f55b5.CyRecorder'>\n",
      "1 loop, best of 3: 27.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve((1000,42,CyRecorder,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Cython helps, but we're nowhere near native C/C++ performance.  The reason is that not all of the above code can be optimized to run as \"pure\" C++.  In particular, Cython's code annotator shows that the loop over diploids will spend a lot of time in Python operations.  The reason for this behavior is that Cython knows nothing about the fwdpp/fwdpy11 C++ types.  To improve performance in Cython, we'd have to make it aware of those types. However, that may be very difficult and/or impossible--I haven't been able to figure out how to get Cython to understand C++ types wrapped by pybind11.  In the end, that is probably OK, as the amount of code needed to wrap C++ types for Cython is more than what is needed to simply write the sampler in C++ and pybind11.\n",
    "\n",
    "## A C++ implementation\n",
    "\n",
    "We now turn to implementing our sampler using C++ and [pybind11](https://pybind11.readthedocs.io/).\n",
    "\n",
    "As with our Cython recorder, we'll have a C-style structure representing our data.  We'll register that structure as a NumPy dtype.  Further, we'll register a vector of that structure as an \"opaque\" container compatible with Python's buffer protocol.  The end result will be that the recorder data will be held in a C++ vector that we can coerce directly to a NumPy structured array.\n",
    "\n",
    "Our C++ code is shown below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. literalinclude:: sampler.cpp\n",
    "    :language: cpp\n",
    "    :lines: 19-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [cppimport](https://github.com/tbenthompson/cppimport) to compile and import our new module under the name \"sampler\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cppimport\n",
    "cppimport.set_quiet(True)\n",
    "sampler = cppimport.imp(\"sampler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sampler.cppRecorder'>\n",
      "<class 'sampler.cppRecorder'>\n",
      "<class 'sampler.cppRecorder'>\n",
      "<class 'sampler.cppRecorder'>\n",
      "1 loop, best of 3: 221 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve((1000,42,sampler.cppRecorder,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at that number. It is almost as fast as running a simulation without a sampler!  There's an important lesson here: if you want to maximize performance, move as much of the computation as possible outside of Python and into C/C++.  Of course, this simply must be the case, given how fwdpy11 is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sanity check\n",
    "\n",
    "Do all of the above recorders give the same results? As usual with floating point calculations, the answer is \"no\" in an absolute sense, and \"yes\" in the sense of numerical precision.\n",
    "\n",
    "Let's get the data from each sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PyRecorder'>\n"
     ]
    }
   ],
   "source": [
    "py1res = pd.DataFrame(evolve((1000,42,PyRecorder,100.,100.,500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PyRecorder2'>\n"
     ]
    }
   ],
   "source": [
    "py2res = pd.DataFrame(evolve((1000,42,PyRecorder2,100.,100.,500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_cython_magic_c1fa566bdd971718f341148a046f55b5.CyRecorder'>\n"
     ]
    }
   ],
   "source": [
    "cyres = pd.DataFrame(evolve((1000,42,CyRecorder,100.,100.,500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sampler.cppRecorder'>\n"
     ]
    }
   ],
   "source": [
    "cppres = pd.DataFrame(np.array(evolve((1000,42,sampler.cppRecorder,100.,100.,500))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results.  We'll look at the max difference for each output column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.12757025938e-17 1.04083408559e-17\n",
      "0.0 1.12757025938e-17 1.04083408559e-17\n",
      "4.32986979604e-15 1.12757025938e-17 8.67361737988e-18\n",
      "0.0 0.0 0.0\n",
      "4.32986979604e-15 9.54097911787e-18 4.33680868994e-18\n",
      "4.32986979604e-15 9.54097911787e-18 4.33680868994e-18\n"
     ]
    }
   ],
   "source": [
    "dfs=[py1res,py2res,cyres,cppres]\n",
    "for i in range(len(dfs)-1):\n",
    "    for j in range(i+1,len(dfs)):\n",
    "        print((dfs[i]['wbar']-dfs[j]['wbar']).max(),\n",
    "              (dfs[i]['s1']-dfs[j]['s1']).max(),\n",
    "              (dfs[i]['s2']-dfs[j]['s2']).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having our cake and eating it, too.\n",
    "\n",
    "The above results show that C++ recorders have the best run-time performance. It is tempting to think that this is a huge problem, implying that you cannot have the incredible flexibility of Python and the high-performance of C++ in the same recorder type.  Well, you can, thanks to [pybind11](https://pybind11.readthedocs.io/).  Let's write a C++ recorder that does the following:\n",
    "\n",
    "1. Like our previous example, it holds the data in structures that can be easily converted to NumPy arrays.\n",
    "2. The C++ object contains a Python function that is called.  This function processes our buffer in some way that only Python can do.\n",
    "\n",
    "We'll show the use of this type in Python first, and save the C++ code for the end.  We will define a callable Python class that takes the buffer from C++, converts it to a NumPy record array, converts that record array to a Pandas DataFrame, and keeps appending to that data frame.\n",
    "\n",
    "We're also doing to demand that our recorder do more work.  It will record the generation number, individual label, individual genetic value, and the sum of effect sizes on each gamete, for each individual in every generation.  In other words, instead of storing a few numbers per generation, we'll store more than $N$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvertToDF(object):\n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame()\n",
    "    def __call__(self,data):\n",
    "        #if self.data is None:\n",
    "        #    self.data = pd.DataFrame(np.array(data))\n",
    "        #else:\n",
    "        self.data = self.data.append(pd.DataFrame(np.array(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this work work, we need our recorder constructor to take a python callable as an argument, and so we have to rework our evolve function a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evolve2(args):\n",
    "    \"\"\"\n",
    "    Evolve function takes an initial\n",
    "    population size,\n",
    "    RNG seed, and the type name of a recorder as\n",
    "    arguments.\n",
    "    \"\"\"\n",
    "    N,seed,recorderType,recorderOptions,theta,rho,simlen=args\n",
    "    pop = fwdpy11.SlocusPop(N)\n",
    "    rng=fwdpy11.GSLrng(seed)\n",
    "    nrate=theta/float(4*N)\n",
    "    recrate=rho/float(4*N)\n",
    "    params=fwdpy11.model_params.SlocusParams(\n",
    "        nregions=[fwdpy11.Region(0,1,1)],\n",
    "        sregions=[fwdpy11.ExpS(0,1,1,-0.1,1.0)],\n",
    "        recregions=[fwdpy11.Region(0,1,1)],\n",
    "        gvalue=fwdpy11.fitness.SlocusAdditive(2.0),\n",
    "        demography=np.array([N]*simlen,dtype=np.uint32),\n",
    "        rates=(nrate,5e-3,recrate))\n",
    "    #This is the difference from the function used above:\n",
    "    ro = recorderOptions()\n",
    "    recorder = recorderType(simlen,ro)\n",
    "    fwdpy11.wright_fisher.evolve(rng,pop,params,recorder)\n",
    "    return ro.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and import our module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler_fxn = cppimport.imp(\"sampler_pyfunction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate a larger $N$, $\\theta$, and $\\rho$ than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 38.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve2((10000,42,sampler_fxn.cppRecorderFunc,ConvertToDF,1000.,1000.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the params we've done all along:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 4.27 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit x=evolve2((1000,42,sampler_fxn.cppRecorderFunc,ConvertToDF,100.,100.,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's pretty good performance, especially considering that our sampler is rather \"dumb\" in the sense that there are better ways to do what it is doing.  (The smarter thing would be to store all the data as a NumPy structured array and grow it using `numpy.concatenate`.  Structured arrays are faster, and require less memory, than DataFrames.  You only need a DataFrame when you need to take advantage of its nice indexing features.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=evolve2((10000,42,sampler_fxn.cppRecorderFunc,ConvertToDF,1000.,1000.,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are indeed $N$ entries per generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "xg=x.groupby(['generation'])\n",
    "for n,g in list(xg)[:3]:\n",
    "    print(len(g.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can process things in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991993659973306 -0.0003946363268985555 -0.00040599767577111095\n",
      "0.9981428395551999 -0.0009885146054695922 -0.0008686458393304458\n",
      "0.9976957480778578 -0.0012369414885845457 -0.0010673104335580225\n"
     ]
    }
   ],
   "source": [
    "for n,g in list(xg)[:3]:\n",
    "    print(g['g'].mean(),g['s1'].mean(),g['s2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does this magic work?  The answer is in the C++ code.  The comments indicate the concepts that distinguish this example from the C++ example above."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. literalinclude:: sampler_pyfunction.cpp\n",
    "    :language: cpp\n",
    "    :lines: 19-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "    This scheme of tying a Python callable to a C++ class means that we need to be careful what our Python callable is \n",
    "    doing.  It must be compatible with the input data. If that requirement is not met, a run-time error will be raised."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
