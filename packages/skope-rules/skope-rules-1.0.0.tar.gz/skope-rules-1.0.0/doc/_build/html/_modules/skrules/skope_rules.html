

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>skrules.skope_rules &mdash; skope_rules 0.1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="skope_rules 0.1.0 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> skope_rules
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">General examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">skope_rules</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>skrules.skope_rules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for skrules.skope_rules</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="k">import</span> <span class="n">warn</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">BaseEstimator</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">check_X_y</span><span class="p">,</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.multiclass</span> <span class="k">import</span> <span class="n">check_classification_targets</span>

<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <span class="n">BaggingClassifier</span><span class="p">,</span> <span class="n">BaggingRegressor</span>

<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="k">import</span> <span class="n">six</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">_tree</span>

<span class="n">INTEGER_TYPES</span> <span class="o">=</span> <span class="p">(</span><span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)</span>


<div class="viewcode-block" id="SkopeRules"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules">[docs]</a><span class="k">class</span> <span class="nc">SkopeRules</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; An easy-interpretable classifier optimizing simple logical rules.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    feature_names : list of str, optional</span>
<span class="sd">        The names of each feature to be used for returning rules in string</span>
<span class="sd">        format.</span>

<span class="sd">    precision_min : float, optional (default=0.5)</span>
<span class="sd">        The minimal precision of a rule to be selected.</span>

<span class="sd">    recall_min : float, optional (default=0.01)</span>
<span class="sd">        The minimal recall of a rule to be selected.</span>

<span class="sd">    n_estimators : int, optional (default=10)</span>
<span class="sd">        The number of base estimators (rules) to use for prediction. More are</span>
<span class="sd">        built before selection. All are available in the estimators_ attribute.</span>

<span class="sd">    similarity_thres : float, optional (default=0.99)</span>
<span class="sd">        Similarity threshold between rules. Rules too similar</span>
<span class="sd">        (&gt; similarity_thres) are fused. The similarity between two rules is</span>
<span class="sd">        computed according to the formula `# {intersection} / # {union}`.</span>

<span class="sd">    max_samples : int or float, optional (default=.8)</span>
<span class="sd">        The number of samples to draw from X to train each decision tree, from</span>
<span class="sd">        which rules are generated and selected.</span>
<span class="sd">            - If int, then draw `max_samples` samples.</span>
<span class="sd">            - If float, then draw `max_samples * X.shape[0]` samples.</span>
<span class="sd">        If max_samples is larger than the number of samples provided,</span>
<span class="sd">        all samples will be used for all trees (no sampling).</span>

<span class="sd">    max_samples_features : int or float, optional (default=1.0)</span>
<span class="sd">        The number of features to draw from X to train each decision tree, from</span>
<span class="sd">        which rules are generated and selected.</span>
<span class="sd">            - If int, then draw `max_features` features.</span>
<span class="sd">            - If float, then draw `max_features * X.shape[1]` features.</span>

<span class="sd">    bootstrap : boolean, optional (default=False)</span>
<span class="sd">        Whether samples are drawn with replacement.</span>

<span class="sd">    bootstrap_features : boolean, optional (default=False)</span>
<span class="sd">        Whether features are drawn with replacement.</span>

<span class="sd">    max_depth : integer or None, optional (default=3)</span>
<span class="sd">        The maximum depth of the decision trees. If None, then nodes are</span>
<span class="sd">        expanded until all leaves are pure or until all leaves contain less</span>
<span class="sd">        than min_samples_split samples.</span>

<span class="sd">    max_features : int, float, string or None, optional (default=&quot;auto&quot;)</span>
<span class="sd">        The number of features considered (by each decision tree) when looking</span>
<span class="sd">        for the best split:</span>

<span class="sd">        - If int, then consider `max_features` features at each split.</span>
<span class="sd">        - If float, then `max_features` is a percentage and</span>
<span class="sd">          `int(max_features * n_features)` features are considered at each</span>
<span class="sd">          split.</span>
<span class="sd">        - If &quot;auto&quot;, then `max_features=sqrt(n_features)`.</span>
<span class="sd">        - If &quot;sqrt&quot;, then `max_features=sqrt(n_features)` (same as &quot;auto&quot;).</span>
<span class="sd">        - If &quot;log2&quot;, then `max_features=log2(n_features)`.</span>
<span class="sd">        - If None, then `max_features=n_features`.</span>

<span class="sd">        Note: the search for a split does not stop until at least one</span>
<span class="sd">        valid partition of the node samples is found, even if it requires to</span>
<span class="sd">        effectively inspect more than ``max_features`` features.</span>

<span class="sd">    min_samples_split : int, float, optional (default=2)</span>
<span class="sd">        The minimum number of samples required to split an internal node for</span>
<span class="sd">        each decision tree.</span>
<span class="sd">            - If int, then consider `min_samples_split` as the minimum number.</span>
<span class="sd">            - If float, then `min_samples_split` is a percentage and</span>
<span class="sd">              `ceil(min_samples_split * n_samples)` are the minimum</span>
<span class="sd">              number of samples for each split.</span>

<span class="sd">    n_jobs : integer, optional (default=1)</span>
<span class="sd">        The number of jobs to run in parallel for both `fit` and `predict`.</span>
<span class="sd">        If -1, then the number of jobs is set to the number of cores.</span>

<span class="sd">    random_state : int, RandomState instance or None, optional</span>
<span class="sd">        - If int, random_state is the seed used by the random number generator.</span>
<span class="sd">        - If RandomState instance, random_state is the random number generator.</span>
<span class="sd">        - If None, the random number generator is the RandomState instance used</span>
<span class="sd">        by `np.random`.</span>

<span class="sd">    verbose : int, optional (default=0)</span>
<span class="sd">        Controls the verbosity of the tree building process.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    rules_ : dict of tuples (rule, precision, recall, nb).</span>
<span class="sd">        The collection of `n_estimators` rules used in the ``predict`` method.</span>
<span class="sd">        The rules are generated by fitted sub-estimators (decision trees). Each</span>
<span class="sd">        rule satisfies recall_min and precision_min conditions. The selection</span>
<span class="sd">        is done according to OOB precisions.</span>

<span class="sd">    estimators_ : list of DecisionTreeClassifier</span>
<span class="sd">        The collection of fitted sub-estimators used to generate candidate</span>
<span class="sd">        rules.</span>

<span class="sd">    estimators_samples_ : list of arrays</span>
<span class="sd">        The subset of drawn samples (i.e., the in-bag samples) for each base</span>
<span class="sd">        estimator.</span>

<span class="sd">    estimators_features_ : list of arrays</span>
<span class="sd">        The subset of drawn features for each base estimator.</span>

<span class="sd">    max_samples_ : integer</span>
<span class="sd">        The actual number of samples</span>

<span class="sd">    n_features_ : integer</span>
<span class="sd">        The number of features when ``fit`` is performed.</span>

<span class="sd">    classes_ : array, shape (n_classes,)</span>
<span class="sd">        The classes labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">feature_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">precision_min</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">recall_min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">similarity_thres</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
                 <span class="n">max_samples</span><span class="o">=.</span><span class="mi">8</span><span class="p">,</span>
                 <span class="n">max_samples_features</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">bootstrap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">bootstrap_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                 <span class="n">max_features</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                 <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                 <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precision_min</span> <span class="o">=</span> <span class="n">precision_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recall_min</span> <span class="o">=</span> <span class="n">recall_min</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">feature_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">similarity_thres</span> <span class="o">=</span> <span class="n">similarity_thres</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">=</span> <span class="n">max_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_samples_features</span> <span class="o">=</span> <span class="n">max_samples_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bootstrap</span> <span class="o">=</span> <span class="n">bootstrap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bootstrap_features</span> <span class="o">=</span> <span class="n">bootstrap_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_features</span> <span class="o">=</span> <span class="n">max_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="n">min_samples_split</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

<div class="viewcode-block" id="SkopeRules.fit"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the model according to the given training data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            Training vector, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like, shape (n_samples,)</span>
<span class="sd">            Target vector relative to X. Has to follow the convention 0 for</span>
<span class="sd">            normal data, 1 for anomalies.</span>

<span class="sd">        sample_weight : array-like, shape (n_samples,) optional</span>
<span class="sd">            Array of weights that are assigned to individual samples, typically</span>
<span class="sd">            the amount in case of transactions data. Used to grow regression</span>
<span class="sd">            trees producing further rules to be tested.</span>
<span class="sd">            If not provided, then each sample is given unit weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Returns self.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">check_classification_targets</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_classes</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;This method needs samples of at least 2 classes&quot;</span>
                             <span class="s2">&quot; in the data, but the data contains only one&quot;</span>
                             <span class="s2">&quot; class: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]):</span>
            <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Found labels </span><span class="si">%s</span><span class="s2">. This method assumes target class to be&quot;</span>
                 <span class="s2">&quot; labeled as 1 and normal data to be labeled as 0. Any label&quot;</span>
                 <span class="s2">&quot; different from 0 will be considered as being from the&quot;</span>
                 <span class="s2">&quot; target class.&quot;</span>
                 <span class="o">%</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># ensure similarity_thres is in (0., 1.]:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_thres</span> <span class="o">&lt;=</span> <span class="mf">1.</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;similarity_thres must be in (0, 1], got </span><span class="si">%r</span><span class="s2">&quot;</span>
                             <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_thres</span><span class="p">)</span>

        <span class="c1"># ensure that max_samples is in [1, n_samples]:</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;max_samples (</span><span class="si">%s</span><span class="s1">) is not supported.&#39;</span>
                             <span class="s1">&#39;Valid choices are: &quot;auto&quot;, int or&#39;</span>
                             <span class="s1">&#39;float&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="n">INTEGER_TYPES</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
                <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;max_samples (</span><span class="si">%s</span><span class="s2">) is greater than the &quot;</span>
                     <span class="s2">&quot;total number of samples (</span><span class="si">%s</span><span class="s2">). max_samples &quot;</span>
                     <span class="s2">&quot;will be set to n_samples for estimation.&quot;</span>
                     <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>
                <span class="n">max_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">max_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># float</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mf">0.</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">&lt;=</span> <span class="mf">1.</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_samples must be in (0, 1], got </span><span class="si">%r</span><span class="s2">&quot;</span>
                                 <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">)</span>
            <span class="n">max_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_samples_</span> <span class="o">=</span> <span class="n">max_samples</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_samples_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_features_</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># default columns names of the form [&#39;c0&#39;, &#39;c1&#39;, ...]:</span>
        <span class="n">feature_names_</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                          <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;c&#39;</span> <span class="o">+</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span> <span class="o">=</span> <span class="n">feature_names_</span>

        <span class="n">bagging_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
            <span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
                <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span>
                <span class="n">min_samples_split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span><span class="p">),</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples_</span><span class="p">,</span>
            <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples_features</span><span class="p">,</span>
            <span class="n">bootstrap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bootstrap</span><span class="p">,</span>
            <span class="n">bootstrap_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bootstrap_features</span><span class="p">,</span>
            <span class="c1"># oob_score=... XXX may be added if selection on tree perf needed.</span>
            <span class="c1"># warm_start=... XXX may be added to increase computation perf.</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="n">bagging_reg</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span>
            <span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeRegressor</span><span class="p">(</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_depth</span><span class="p">,</span>
                <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_features</span><span class="p">,</span>
                <span class="n">min_samples_split</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">min_samples_split</span><span class="p">),</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">,</span>
            <span class="n">max_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples_</span><span class="p">,</span>
            <span class="n">max_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_samples_features</span><span class="p">,</span>
            <span class="n">bootstrap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bootstrap</span><span class="p">,</span>
            <span class="n">bootstrap_features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bootstrap_features</span><span class="p">,</span>
            <span class="c1"># oob_score=... XXX may be added if selection on tree perf needed.</span>
            <span class="c1"># warm_start=... XXX may be added to increase computation perf.</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>

        <span class="n">bagging_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># define regression target:</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">sample_weight</span> <span class="o">-</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="n">contamination</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">y_reg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nb">pow</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">contamination</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span>
                <span class="nb">pow</span><span class="p">((</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
            <span class="n">y_reg</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y_reg</span><span class="p">))</span>  <span class="c1"># sigmoid</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_reg</span> <span class="o">=</span> <span class="n">y</span>  <span class="c1"># same as an other classification bagging</span>

        <span class="n">bagging_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">+=</span> <span class="n">bagging_clf</span><span class="o">.</span><span class="n">estimators_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">+=</span> <span class="n">bagging_reg</span><span class="o">.</span><span class="n">estimators_</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_samples_</span> <span class="o">+=</span> <span class="n">bagging_clf</span><span class="o">.</span><span class="n">estimators_samples_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_samples_</span> <span class="o">+=</span> <span class="n">bagging_reg</span><span class="o">.</span><span class="n">estimators_samples_</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_features_</span> <span class="o">+=</span> <span class="n">bagging_clf</span><span class="o">.</span><span class="n">estimators_features_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_features_</span> <span class="o">+=</span> <span class="n">bagging_reg</span><span class="o">.</span><span class="n">estimators_features_</span>

        <span class="n">rules_</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">features</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">estimators_samples_</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">estimators_features_</span><span class="p">):</span>

            <span class="c1"># Create mask for OOB samples</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">samples</span>
            <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;OOB evaluation not possible: doing it in-bag.&quot;</span>
                     <span class="s2">&quot; Performance evaluation is likely to be wrong&quot;</span>
                     <span class="s2">&quot; (overfitting) and selected rules are likely to&quot;</span>
                     <span class="s2">&quot; not perform well! Please use max_samples &lt; 1.&quot;</span><span class="p">)</span>
                <span class="n">mask</span> <span class="o">=</span> <span class="n">samples</span>
            <span class="n">rules_from_tree</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tree_to_rules</span><span class="p">(</span>
                <span class="n">estimator</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)[</span><span class="n">features</span><span class="p">])</span>

            <span class="c1"># XXX todo: idem without dataframe</span>
            <span class="n">X_oob</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="p">:])[:,</span> <span class="n">features</span><span class="p">],</span>
                                     <span class="n">columns</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)[</span><span class="n">features</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">X_oob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># otherwise pandas bug (cf. issue #16363)</span>
                <span class="n">y_oob</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
                <span class="n">y_oob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="n">y_oob</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>

                <span class="c1"># Add OOB performances to rules:</span>
                <span class="n">rules_from_tree</span> <span class="o">=</span> <span class="p">[(</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_rule_perf</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">X_oob</span><span class="p">,</span> <span class="n">y_oob</span><span class="p">))</span>
                                   <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">rules_from_tree</span><span class="p">)]</span>
                <span class="n">rules_</span> <span class="o">+=</span> <span class="n">rules_from_tree</span>

        <span class="c1"># keep only rules verifying precision_min and recall_min:</span>
        <span class="k">for</span> <span class="n">rule</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">rules_</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">precision_min</span> <span class="ow">and</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recall_min</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">rule</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">:</span>
                    <span class="c1"># update the score to the new mean</span>
                    <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
                    <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span>
                        <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span>
                        <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">rule</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                             <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># removing rules which have very similar domains</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">))</span>
        <span class="n">omit_these_rules_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">perimeter_index_of_all_rules</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">)):</span>
            <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">perimeter_index_of_all_rules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">current</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
                <span class="p">)</span>
            <span class="n">index_current</span> <span class="o">=</span> <span class="n">perimeter_index_of_all_rules</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">omit_these_rules_list</span><span class="p">:</span>
                    <span class="k">continue</span>
                    <span class="c1"># if a rule have already been discarded,</span>
                    <span class="c1"># it should not be processed again</span>

                <span class="n">index_rival</span> <span class="o">=</span> <span class="n">perimeter_index_of_all_rules</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="n">size_union</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">index_rival</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">index_current</span><span class="p">))</span>
                <span class="n">size_intersection</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">index_rival</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">index_current</span><span class="p">))</span>

                <span class="k">if</span> <span class="nb">float</span><span class="p">(</span><span class="n">size_intersection</span><span class="p">)</span><span class="o">/</span><span class="n">size_union</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">similarity_thres</span><span class="p">:</span>
                    <span class="n">omit_these_rules_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">omit_these_rules_list</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SkopeRules.predict"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict if a particular sample is an outlier or not.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The input samples. Internally, it will be converted to</span>
<span class="sd">            ``dtype=np.float32``</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        is_outlier : array, shape (n_samples,)</span>
<span class="sd">            For each observations, tells whether or not (1 or 0) it should</span>
<span class="sd">            be considered as an outlier according to the selected rules.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span></div>

<div class="viewcode-block" id="SkopeRules.decision_function"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.decision_function">[docs]</a>    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Average anomaly score of X of the base classifiers (rules).</span>

<span class="sd">        The anomaly score of an input sample is computed as</span>
<span class="sd">        the weighted sum of the binary rules outputs, the weight being</span>
<span class="sd">        the respective precision of each rule.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The training input samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scores : array, shape (n_samples,)</span>
<span class="sd">            The anomaly score of the input samples.</span>
<span class="sd">            The higher, the more abnormal. Positive scores represent outliers,</span>
<span class="sd">            null scores represent inliers.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if fit had been called</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;rules_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_samples_&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;max_samples_&#39;</span><span class="p">])</span>

        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X.shape[1] = </span><span class="si">%d</span><span class="s2"> should be equal to </span><span class="si">%d</span><span class="s2">, &quot;</span>
                             <span class="s2">&quot;the number of features at training time.&quot;</span>
                             <span class="s2">&quot; Please reshape your data.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>
        <span class="n">selected_rules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">selected_rules</span><span class="p">:</span>
            <span class="n">scores</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)]</span> <span class="o">+=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">scores</span></div>

<div class="viewcode-block" id="SkopeRules.rules_vote"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.rules_vote">[docs]</a>    <span class="k">def</span> <span class="nf">rules_vote</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Score representing a vote of the base classifiers (rules).</span>

<span class="sd">        The score of an input sample is computed as the sum of the binary</span>
<span class="sd">        rules outputs: a score of k means than k rules have voted positively.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The training input samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scores : array, shape (n_samples,)</span>
<span class="sd">            The score of the input samples.</span>
<span class="sd">            The higher, the more abnormal. Positive scores represent outliers,</span>
<span class="sd">            null scores represent inliers.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if fit had been called</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;rules_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_samples_&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;max_samples_&#39;</span><span class="p">])</span>

        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X.shape[1] = </span><span class="si">%d</span><span class="s2"> should be equal to </span><span class="si">%d</span><span class="s2">, &quot;</span>
                             <span class="s2">&quot;the number of features at training time.&quot;</span>
                             <span class="s2">&quot; Please reshape your data.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>
        <span class="n">selected_rules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">selected_rules</span><span class="p">:</span>
            <span class="n">scores</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">scores</span></div>

<div class="viewcode-block" id="SkopeRules.score_top_rules"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.score_top_rules">[docs]</a>    <span class="k">def</span> <span class="nf">score_top_rules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Score representing an ordering between the base classifiers (rules).</span>

<span class="sd">        The score is high when the instance is detected by a performing rule.</span>
<span class="sd">        If there are n rules, ordered by increasing OOB precision, a score of k</span>
<span class="sd">        means than the kth rule has voted positively, but not the (k-1) first</span>
<span class="sd">        rules.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The training input samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scores : array, shape (n_samples,)</span>
<span class="sd">            The score of the input samples.</span>
<span class="sd">            Positive scores represent outliers, null scores represent inliers.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if fit had been called</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;rules_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_&#39;</span><span class="p">,</span> <span class="s1">&#39;estimators_samples_&#39;</span><span class="p">,</span>
                               <span class="s1">&#39;max_samples_&#39;</span><span class="p">])</span>

        <span class="c1"># Input validation</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;X.shape[1] = </span><span class="si">%d</span><span class="s2"> should be equal to </span><span class="si">%d</span><span class="s2">, &quot;</span>
                             <span class="s2">&quot;the number of features at training time.&quot;</span>
                             <span class="s2">&quot; Please reshape your data.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_names_</span><span class="p">)</span>
        <span class="n">selected_rules</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rules_</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">((</span><span class="n">selected_rules</span><span class="p">))):</span>
            <span class="n">scores</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">index</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">selected_rules</span><span class="p">)</span> <span class="o">-</span> <span class="n">k</span><span class="p">,</span>
                <span class="n">scores</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">index</span><span class="p">)])</span>

        <span class="k">return</span> <span class="n">scores</span></div>

<div class="viewcode-block" id="SkopeRules.predict_top_rules"><a class="viewcode-back" href="../../skope_rules.html#skrules.skope_rules.SkopeRules.predict_top_rules">[docs]</a>    <span class="k">def</span> <span class="nf">predict_top_rules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_rules</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict if a particular sample is an outlier or not,</span>
<span class="sd">        using the n_rules most performing rules.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like, shape (n_samples, n_features)</span>
<span class="sd">            The input samples. Internally, it will be converted to</span>
<span class="sd">            ``dtype=np.float32``</span>

<span class="sd">        n_rules : int</span>
<span class="sd">            The number of rules used for the prediction. If one of the</span>
<span class="sd">            n_rules most performing rules is activated, the prediction</span>
<span class="sd">            is equal to 1.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        is_outlier : array, shape (n_samples,)</span>
<span class="sd">            For each observations, tells whether or not (1 or 0) it should</span>
<span class="sd">            be considered as an outlier according to the selected rules.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">score_top_rules</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rules_</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_rules</span><span class="p">),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_tree_to_rules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of rules from a tree</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            tree : Decision Tree Classifier/Regressor</span>
<span class="sd">            feature_names: list of variable names</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rules : list of rules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># XXX todo: check the case where tree is build on subset of features,</span>
        <span class="c1"># ie max_features != None</span>

        <span class="n">tree_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">tree_</span>
        <span class="n">feature_name</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span> <span class="k">else</span> <span class="s2">&quot;undefined!&quot;</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span>
        <span class="p">]</span>
        <span class="n">rules</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span> <span class="nf">recurse</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">base_name</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">tree_</span><span class="o">.</span><span class="n">feature</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">!=</span> <span class="n">_tree</span><span class="o">.</span><span class="n">TREE_UNDEFINED</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">feature_name</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
                <span class="n">symbol</span> <span class="o">=</span> <span class="s1">&#39;&lt;=&#39;</span>
                <span class="n">symbol2</span> <span class="o">=</span> <span class="s1">&#39;&gt;&#39;</span>
                <span class="n">threshold</span> <span class="o">=</span> <span class="n">tree_</span><span class="o">.</span><span class="n">threshold</span><span class="p">[</span><span class="n">node</span><span class="p">]</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">base_name</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">symbol</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)]</span>
                <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_left</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">text</span><span class="p">)</span>

                <span class="n">text</span> <span class="o">=</span> <span class="n">base_name</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">symbol2</span><span class="p">,</span>
                                                      <span class="n">threshold</span><span class="p">)]</span>
                <span class="n">recurse</span><span class="p">(</span><span class="n">tree_</span><span class="o">.</span><span class="n">children_right</span><span class="p">[</span><span class="n">node</span><span class="p">],</span> <span class="n">text</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">rule</span> <span class="o">=</span> <span class="nb">str</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39; and &#39;</span><span class="p">,</span> <span class="n">base_name</span><span class="p">)</span>
                <span class="n">rule</span> <span class="o">=</span> <span class="p">(</span><span class="n">rule</span> <span class="k">if</span> <span class="n">rule</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span>
                        <span class="k">else</span> <span class="s1">&#39;==&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
                <span class="c1"># a rule selecting all is set to &quot;c0==c0&quot;</span>
                <span class="n">rules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span>

        <span class="n">recurse</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[])</span>

        <span class="k">return</span> <span class="n">rules</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;True&#39;</span>

    <span class="k">def</span> <span class="nf">_eval_rule_perf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rule</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">detected_index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">rule</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">detected_index</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">y_detected</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">detected_index</span><span class="p">]</span>
        <span class="n">true_pos</span> <span class="o">=</span> <span class="n">y_detected</span><span class="p">[</span><span class="n">y_detected</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">true_pos</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">y_detected</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="nb">float</span><span class="p">(</span><span class="n">true_pos</span><span class="p">)</span> <span class="o">/</span> <span class="n">pos</span></div>
</pre></div>

           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>