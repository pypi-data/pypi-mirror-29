*Natural Language Processing in Action*

*Hobson Lane, Cole Howard, and Hannes Hapke*

*1. Tell us about yourself.*

* ___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Hobson has more than 15 years of experience building autonomous systems
that make important decisions on behalf of humans. At
http://talentpair.com[_Talentpair_] Hobson teaches machines to read and
understand resumes with more patience, consistency, and less bias than
most humans. Hobson is passionate about openness and AI. He’s an active
contributor to Open Source, Open Science projects such as Keras, SciKit
Learn, PyBrain, PUGNLP, and ChatterBot. He has published papers and
presented talks at
http://mstl.atl.calpoly.edu/~workshop/archive/2006/Spring/12-Lane-Nanosat.pdf[_AIAA_],
https://us.pycon.org/2016/schedule/presentation/1778/[_PyCon_],
https://www.academia.edu/attachments/36858143/download_file?st=MTQ3NDQ4ODkzMyw2Ny4xMzYuMTI5LjE5NiwxMTMzNDc5NQ%3D%3D&s=swp-preview-selector-dropdown[_PAIS_],
and http://rjwagner49.com/Iris/SRW-Paper-13.pdf[_IEEE_] and has been
awarded http://patents.justia.com/inventor/hobson-lane[_numerous
patents_] in Robotics and Automation.
___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
* _____________________________________________________________________________________________________________________________________________________________________________________________________________________
Hobson’s first childhood dream was to sail around the world. Having
accomplished that, he’s now pursuing his second dream, building friendly
bots that can have intelligent conversations with humans and each other.
_____________________________________________________________________________________________________________________________________________________________________________________________________________________
* _____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
https://www.linkedin.com/in/hanneshapke[_Hannes_] is an Electrical
Engineer turned Data Scientist with _deep_ experience in _deep_
learning. Neural networks changed his life. He became fascinated with
neural networks while investigating novel ways to control renewable
energy power plants effectively in High School. Hannes loves to automate
software development and machine learning pipelines. He’s the one you
can thank for all the time-saving tips and “scaling” advice in this book
as well as integration of the Chatbot microservices with SMS messaging.
He’s a regular speaker at conferences like PyCon, Hack University, and
http://opensourcebridge.org/users/1588[_Open Source Bridge_], and he’s
continually climbing the leaderboard at Kaggle using the tools he
developed for this book.
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
* _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
https://www.linkedin.com/in/uglyboxer[_Cole_] is a carpenter and writer
turned Data Scientist and Deep Learning expert. A lifelong hunter of
patterns, he found his true home in the world of Artificial Neural
Networks. He has developed large-scale e-commerce recommendation engines
and state-of-the-art neural nets for hyperdimensional machine
intelligence systems (“deep learning” neural nets) which perform at the
top of the leader board for the Kaggle competitions. He has presented
talks on Convolutional Neural Nets, Recurrent Neural Nets and their
roles in natural language processing at the
http://opensourcebridge.org/users/2606[_Open Source Bridge Conference_]
and Hack University. He currently is deeply fascinated by the shape of
memory in a neural network.
_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
* ____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Like our target audience, the authors are all self-taught experts in
Machine Intelligence (Artificial Intelligence, Deep Learning, pick your
buzzword) and achieved success by teaching those around them and
exploring resources available from publishers such as Manning.
____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

*2. Tell us about the book.*

* ____________________________________________________________________________________________________________________________________________________________________________________________________________________
We want to show the reader how to build a system that can read,
"understand", and compose meaningful, English text, and we want to
explain why contributing to an ecosystem of these prosocial bots is so
important.
____________________________________________________________________________________________________________________________________________________________________________________________________________________
* ___________________________________________________________________________________________________________________________________________________________________________________________
This book will show developers (and budding data scientists) how to
build machines that understand and act intelligently on information
gleaned from natural language. These machines will:
___________________________________________________________________________________________________________________________________________________________________________________________
** ______________
Compose tweets
______________
** ______________
Summarize text
______________
** _______________________________________
Participate in conversations on Twitter
_______________________________________
** ________________
Answer questions
________________
** ________________________________________
Gage the sentiment of English statements
________________________________________
** ________________________________________________
Gage the sensitivity and kindness of a statement
________________________________________________
** ____________________________________________________________________________
Estimate the era or “cultural context” of a music lyric or colloquial
phrase
____________________________________________________________________________
** __________________________________________________________
Predict the human reaction to a natural language statement
__________________________________________________________
** _______________________________________
Compose passages for books such as this
_______________________________________

_________________________________________________________________________________________________________________________________________________________________________________________________
Both the “how” and “why” of these machines will be explained to the
reader. Readers will build the intuition and skills required to extend
the capability of the tools demonstrated in this book.
_________________________________________________________________________________________________________________________________________________________________________________________________

* _________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Machines must be taught to understand human conversation and communicate
with us in helpful ways if we can expect them to be supportive of us in
the future. Propagating and “diversifying the genome” of prosocial,
natural-language-aware machines helps ensure a bright future for
humanity in cooperation with machines, and may accelerate the discovery
of technological solutions to pressing societal challenges.
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
* ______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
There are 2 mathematical techniques for compressing high dimensional
data (the millions of dimensions of data contained in all the possible
natural language phrases and their meaning) into a small number of
topics or “meanings” that can be acted on by a machine.
______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
** ___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Statistical or Data-Based: A large amount of data (texts) can be
processed by a machine without human supervision to train machines to
behave intelligently, but the volume of text required grows with the
complexity/intelligence of the behavior desired
___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
** __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Ontology and Grammar-Based: Grammar-based techniques depend on a large
and flexible ontology of information about the world and words to
describe that information as well as the grammar rules for communication
of those facts. This ontology usually requires significant human
curation, but smaller ontologies can be assembled from open sources
without much effort and significantly improve the performance of chat
bots.
__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
This book will show the reader how to build a pipeline built on both of
these two approaches and includes a sufficient volume of accurate data
to achieve satisfactory results on each of the tasks outlined. Other
books about natural language processing leave the training and data
acquisition as an “exercise for the reader” and often only discuss toy
problems or simplified applications. In contrast, this book will show
the reader how to build fully-trained end-to-end natural language
pipelines capable of prediction tasks with reasonable accuracy and
interactive dialog in domains sufficiently broad to be useful and
interesting. It will explain each step required to build an intelligent,
https://docs.google.com/document/d/1Gn3w2OOyHaCfQxOGJwaLbou_-PdUVNZyrtvujm8-1w4/edit?ts=57be90a9[_prosocial
machine_], including the “answer” in the form of a library of open
source software packages that accomplishes the training and system
implementation described in the book. Each software package will include
links to the open data sources (machine-readable corpora and training
sets) that were used to train it as well as fully functional online APIs
(microservices) to each of the pieces of the pipeline. Only by building
and interacting with this intelligent machine can the reader develop an
intuition and understanding of the underlying principles that make it
possible.
______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

* ___________________________________________________________________________
This book will be an *“In Action”* tutorial best read with a laptop
nearby.
___________________________________________________________________________
** __________________________________________________________________________________________________________________________________________________________________________________________________________
Example implementations of the tools the book describes will be open
sourced under a liberal license (MIT) and deployed as web apps and APIs
for the reader to play with and modify while reading the book
__________________________________________________________________________________________________________________________________________________________________________________________________________
** _____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
The tools the book describes will be used to write the book! Some of the
text within the book will have been corrected and edited by these tools.
It may even be possible to have the closing and opening paragraphs
written entirely by one of these tools (the text summarizer), without
any human interaction, justifying a sensational title such as “A
Book-Writing Machine In Action” or “Learn How to Build a Machine that
can Write a Book Like This”
_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

*3. Tasks in the domain of this book*

* ___________________________________________________________
Acquire, clean, and label a “reading list” for your machine
___________________________________________________________
* _______________________________________________________________
Visualize statistics and patterns in your corpus (reading list)
_______________________________________________________________
* ___________________________________________________________
Train the machine to glean “meaning” from this reading list
___________________________________________________________
* ___________________________________________________________
Visualize the domain of knowledge your machine has attained
___________________________________________________________
* _______________________________________________________________________________________________________________________________
Train the machine to perform useful NL tasks (such as composing new text
or predicting reader reaction to an English statement)
_______________________________________________________________________________________________________________________________
* ____________________________________________________________________________________________________________________________
Construct a neural network appropriate for training on natural language
texts for performing many of the tasks in this book.
____________________________________________________________________________________________________________________________
* __________________________________________________________
Generate a summary of a large document (such as this book)
__________________________________________________________
* _________________________________________________________________________________________________________________________
Generate phrases with the meaning requested by a user in the style of
those from a subset of one’s reading list (corpus).
_________________________________________________________________________________________________________________________
* ___________________________________________________________________________________________________________________________________________________________________________________________________
Suggest phrasing and rewording of existing texts to optimize for some
measure of quality such as readability, grammaticality, an empathetic
tone, style-similarity to another text, or conciseness.
___________________________________________________________________________________________________________________________________________________________________________________________________

*4. The minimally-qualified reader (MQR)*

The MQR will have knowledge of High School algebra and have had some
exposure to vectors and matrices as well as simple statistical measures
such as mean and variance (or standard deviation). They will also have
programmed in some modern programming language, such as C++, Python,
Java, or Javascript. They will have seen a “curve fit” or linear
regression and understand that it is possible for a simple machine (such
as a programmable calculator) to calculate the slope and “offset” of a
line that most closely “fits” data presented in a 2-D scatter plot. They
will have seen a formula for a line such as `y = a * x + b` before. They
will have an aptitude for interpreting graphs and connecting the
patterns they see to the statistics they can compute in a computer
programming language (like the min, max, mean and variance).

* ____________________________________________________________________________________________________________________________________
The ideal MQR will be a University or advanced high-school student with
a passion for solving technical (math and science) problems.
____________________________________________________________________________________________________________________________________

*The MQR will know basic math + computer science concepts*

* ______________________________________________
Vectors (arrays) & Matrices (arrays of arrays)
______________________________________________
* ___________________________________________________________________
Sets (unordered arrays when all elements are unique within the set)
___________________________________________________________________
* _______
Strings
_______
* _______________________________________________
Arrays, Functions, Classes, Loops, Conditionals
_______________________________________________

*The MQR will know basic English language concepts*

* _________________________________
Words, Nouns, Verbs, Proper Nouns
_________________________________
* __________________
Sentences, Phrases
__________________
* _____________________________________
Contractions, Abbreviations, Acronyms
_____________________________________
* ___________________________________
Possessive Word Forms, Plural Forms
___________________________________
* ____________________________________________________________________________
A grammar rule or two (such as one or two requirements for a valid
sentence)
____________________________________________________________________________

*The MQR will not be required to be a proficient python programmer, but
should know (or quickly figure out) how to install and run python
packages on their machine.*

*5. Q&A*

How is it possible to build a machine that can compose valid sentences
without teaching it all the rules of English grammar and the logic
behind the meaning of all the words in the English language? How is it
possible for a machine to interact with other humans in a chatroom
without sounding mechanical, repetitive, “programmed”?

*6. Tell us about the competition and the ecosystem.*

* ____________________________________________________________________________________________________________________
Numerous books on Natural Language Processing are available, including
several that teach the use of python for NLP?
____________________________________________________________________________________________________________________
* _________________________________________________________________________________________________________________________________________________________________________________________________________________________________
It provides a working state-of-the-art system including the data
required to make it viable and intelligent. And it provides insights
into human cognition and analogous machine intelligence processes that
other books neglect.
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________
* _______________________________
My favorite books on the topic:
_______________________________
** ______________________________________________________________________________________
Jurafsky’s _Speech and Language Processing_ Manning’s _Foundations of
Statistical NLP_
______________________________________________________________________________________
** __________________________________
Grus’s _Data Science from Scratch_
__________________________________
** _____________________________________________________________
Russel & Norvig’s _Artificial Intelligence a Modern Approach_
_____________________________________________________________
** ________________________________________________
Bird’s _Natural Language Processing with Python_
________________________________________________
** ________________________________________________________
Perkins’ _Python 3 Text Processing with NLTK 3 Cookbook_
________________________________________________________
* _______________________________________________________________________________
What are the most important web sites and companies associated with this
topic?
_______________________________________________________________________________
** _________________________________________________________________________________________
Coursera: e.g.
https://www.coursera.org/learn/natural-language-processing[_intro to
NLP_]
_________________________________________________________________________________________
** _________________________________________________________________________________
Kaggle: e.g. https://www.kaggle.com/c/word2vec-nlp-tutorial[_word2vec on
movies_]
_________________________________________________________________________________
** _______________________________________________________________________________________________________
Udacity: e.g.
http://catalog.oregonstate.edu/CourseDetail.aspx?subjectcode=CS&coursenumber=271[_cs271_]
_______________________________________________________________________________________________________
** _______________________________________________________________________________________________________________________________________________________________
MIT Open Courseware: e.g.
http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-864-advanced-natural-language-processing-fall-2005/[_6-864_]
_______________________________________________________________________________________________________________________________________________________________
** _____________________________________________________________________________________________
Carnegie Mellon Univ.: http://rtw.ml.cmu.edu/rtw/kbbrowser/[_Never
Ending Language Learning_]
_____________________________________________________________________________________________
** ___________________________________________________________________
Princeton Univ.: Chomsky, https://wordnet.princeton.edu/[_WordNet_]
___________________________________________________________________
** ________________________________________________________________________________________________________________________________________
Stanford Univ.: http://web.stanford.edu/class/cs224n/[_cs224n_],
Jurafsky’s http://web.stanford.edu/class/cs124/lec/chatbot.pdf[_cs124_]
________________________________________________________________________________________________________________________________________
** _______
Google:
_______
*** ________________________________________________________________________________
https://cloud.google.com/natural-language/[_cloud.google.com/natural-language/_]
________________________________________________________________________________
*** ________________________________________________________________________________________________________________________
https://radimrehurek.com/gensim/models/word2vec.html[_W_]https://radimrehurek.com/gensim/models/word2vec.html[_ord2vec_]
________________________________________________________________________________________________________________________
*** ___________________________________________________________________
http://norvig.com/spell-correct.html[_Norvig’s spelling corrector_]
___________________________________________________________________
*** ___________________________________________________________________________________________________________
http://storage.googleapis.com/books/ngrams/books/datasetsv2.html[_NGram
Viewer API_] 15% of all books ever!
___________________________________________________________________________________________________________
** ________________________________________________________________________________
Gensim package: https://radimrehurek.com/gensim/tutorial.html[_gensim
tutorial_]
________________________________________________________________________________
** ______________________________________________________________
http://saifmohammad.com/WebPages/lexicons.html[_Lexica Links_]
______________________________________________________________
** ____________________________________________________________________________________________________
https://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs[_Gutenberg
project_] All books before 1940
____________________________________________________________________________________________________
** ______________
Microsoft: Tai
______________
* _______________________________________________________
Where do others interested in this topic gather online?
_______________________________________________________
** ________
Coursera
________
** ______
Kaggle
______
** _______
Udacity
_______
** _______________
Hack University
_______________
** _______________________________
Local Python User Group Meetups
_______________________________

*7. Book size*

* _________
300 pages
_________
* _______________________________________
80 diagrams, tables, pictures, graphics
_______________________________________
* _______________________
150 short code snippets
_______________________

*8. Contact information*

______________________________________________________________________________________________________
Names on contract: Hobson Lane, Cole Howard, Hannes Hapke

Names on cover: (same)

Total Good

2004 SW Jefferson St #614

Portland, OR 97201

Phone: 503.974.6274

Skype: codeninja1

Nonprofit:
http://totalgood.com/[_total_]http://totalgood.com/[_≡_]http://totalgood.com/[*_GOOD_*]

Blog: https://github.com/hobson[_hobsonlane.com_]

LinkedIn:
https://www.linkedin.com/in/hobsonlane[_linkedin.com/in/hobsonlane_]

Github: https://github.com/totalgood[_github.com/totalgood_]

Twitter: https://twitter.com/hobsonlane[_@hobsonlane_] and
https://twitter.com/goodtotal[_@goodtotal_]

Stack Exchange: http://stackoverflow.com/users/623735/hobs[_@hobs_]
______________________________________________________________________________________________________

*9. Schedule*

* ___________
14 Chapters
___________
** ______________
Ch 1: Oct 15th
______________
** ______________
Ch 2: Oct 31st
______________
** _______________________________
⅓ manuscript (Ch 1-5): Jan 31st
_______________________________
** __________________________________
⅔ manuscript (Ch 6-10): March 31st
__________________________________
** _______________________________________
Complete manuscript (Ch 1-14): May 18th
_______________________________________
* _________________________________________________________________
Are there any critical deadlines for the completion of this book?
_________________________________________________________________
** ___________________________________________________________
Several competitors likely to publish on this topic in 2017
___________________________________________________________
** _________________________________________________________________
PyCon 2017 May 18th (when we will present excerpts from the book)
_________________________________________________________________

*10. Table of Contents*

__________________________________
*A Book-Writing Machine in Action*
__________________________________

Part 1 First steps

1 Natural Language Processing

_____________________________________________________
1.1 What is Natural Language Processing

1.2 Grammar-based Approaches (historical perspective)

1.3 Statistical Approaches
_____________________________________________________

2 Machines that Understand Text

______________________________________________________________
2.1 The Magic behind Google Search

2.2 Math with Words (Word2Vec)

2.3 Writing Assistance (Hemingway App, Resume Writing Coaches)
______________________________________________________________

Part 2 Your Bot’s Summer Reading List

3 Acquiring Words

___________________________________________________________________
3.1 Finding Corpora and Lexica without undue copyright restrictions

3.2 Labeled Corpora and Lexica

3.3 Scraping and cleaning text

3.4 Twitter

3.5 Google NGram API

3.6 Gutenberg Project

3.7 Storage
___________________________________________________________________

4 Build Your Vocabulary

___________________________________________
4.1 Overview of a NLP pipeline

4.2 Tokenization and Character-Level Models

4.2 Word Stemming and Case Normalization

4.3 Semantic stemming
___________________________________________

4.3 Transcoding (e.g. slang words/phrases; POS tagging; word
disambiguation)

_____________________________________________________
4.4 N-Grams and Bags of Words

4.5 TFIDF: Frequency Counting and Statistical Filters

4.6 Rare words, Proper Nouns, and IDs (URLs)

4.7 Common words (stop words)

4.8 Zipf’s Law

4.9 Interesting Word-Usage Stats, History
_____________________________________________________

5 Chunking

________________________________________
5.1 Sentence Segmentation

5.2 Paragraph/Chapter/Topic Segmentation

5.3 What makes a Document? Context?

5.4 Unsupervised Labeling/Clustering
________________________________________

6 Semantics

____________________________________________________________
6.1 SVD and PCA

6.2 Latent Semantic Indexing, Principle Component Regression

6.3 Topic Vector Magic
____________________________________________________________

7 You Slice, I Choose

_________________________________________________
7.1 Linear Regression

7.2 Nonlinear Regression on Large Data Sets (SGD)

7.3 Logistic Regression

7.4 Support Vector Machines
_________________________________________________

Part 3 Communicating in the Wild

8 Style and Tone

______________________
8.1 Sentiment Analysis

8.2 Sarcasm Detection
______________________

8.3 https://github.com/totalgood/twip[_Choosing Favorites_]

8.4 Imitating the Manning Corpus of Technical Books

9 Making Decisions (Finite State Machines)

_________________________________________________________________________________________________________________________________________________________________________________
9.1 http://stackoverflow.com/a/525029/623735[_Regular Expressions_]

9.2 http://www.nltk.org/book/ch08.html[_Generative Grammar_]

9.3 http://web.stanford.edu/class/cs124/lec/chatbot.pdf[_Finite State
Machines_] for dialog management (AKA phone trees)

9.4 Took the Words Out of My Mouth
(https://veekaybee.github.io/markov-in-python/[_predictive text_] with a
http://www.stat.purdue.edu/~mdw/CSOI/MarkovLab.html[_Markov Models_])
_________________________________________________________________________________________________________________________________________________________________________________

10 Special Agent Chatty

10.1 Goal-based dialog (e.g. x.ai, MS paperclip, Google Search)

10.2 http://www.aclweb.org/anthology/Y13-1042[_Question Answering_]

10.2 https://github.com/gunthercox/ChatterBot[_Let’s Chat_]
(conversation agents)

10.3 http://www.thesarcasmdetector.com/about/[_Sarcasm_] and Humor

11
http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/[_Neural
Nets_]

________________________________________________________________________________________________________________________________
11.1
https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html[_Deep
Learning_]

11.2 CNNs

11.3 RNNs

11.4 LSTMs

11.5 Word2Vec
________________________________________________________________________________________________________________________________

12 A Sounding Board

________________________________
12.1 Grammar filters

12.2 Style/Sentiment filters

12.3 Adversarial Neural Networks
________________________________

13 Hyperparameter Optimization

__________________________
13.1 Heuristics

13.2 Semi-random Search

13.3 Never-Ending Learning
__________________________

14 Playing Out of Your League (Scaling)

____________________________________________________
14.1 Distributed Approaches

14.2 Hyper parallelization (GPUs)

14.3 Problem segmentation (analogous to brain lobes)
____________________________________________________

\15. Summary

15.1 What You’ve Learned

15.2 What Your Bot Has Learned (My Bot Wrote this Section)

15.3 What Next?
